# EvolutionaryRobotics
Watch the full project here: https://www.youtube.com/playlist?list=PLGSjL0wW0EJZ4vTV14MjJsa62t2cHl_hE
Predator and Prey: Creating two robots that learn how to walk and interact with each other.

	For my final project of evolutionary robotics, I decided to work on the idea of predator and prey. This means that one robot would be a predator, while the other robot will be the prey. The predators job would be to reduce the distance between it and the prey, and the prey is trying to maximize the distance between it and the predator. To do so I split the task into separate deliverables. The first deliverable would be to create a prey robot and modify the original robot we created in previous projects to be the predator. The prey robot would have to be a newly created robot called to the simulator and be placed in a different starting position. I placed the prey 5 spaces ahead of the starting robot in the y direction. I made the predator robot red, and the prey robot blue. The next deliverable was to figure out how to have one robot chase the other. I decided to use a light sensor and attached it to the predator, and the prey would contain a light source. It’s similar to a eagle eye type of situation, where the predator will always see where the prey is. As for the prey I had it evolve to walk as far as it can in the opposite direction of where the predator is. The last deliverable was to run the test. For my genetic algorithm I had a population of five and ran the test at different numbers of generations: 500, 1000, and 2000. Soon after I realized that having the prey robot in one starting position doesn’t really show evolution, so I had an extra deliverable of creating multiple environments where the prey is in different locations. I got real close to my end goal, but the prey robot doesn’t do as good as it did before the multiple environments was implemented. The prey robot moves a short distance and then stops.
	To create the prey robot, I simply created a separate class and copied the predator code into it but with a lot of changes. First, I had to change the location of all the body parts and joints. I moved the robot 5 units in the y direction, was as simple as adding 5+ to the current y condition of every object and joint. Also, I removed the light sensor that the predator had included, and replaced it with a light source, and attached it to the main body. My phototaxis experiment code needed some changes. The competition between two randomly chosen robots and their fitness wasn’t working so well, so I had to fix that. Also, the print of the best robot at the end of all the runs was only printing the first child, so I had fixed that. I made the population size five that way the random selection can reach every child faster. One challenge was when I had to implement different environments for the prey. I decided to reuse the code that originally spawned a light source block. I modified it to where when a certain environment number is called, it would call the corresponding robot to the simulation. This was the hardest part, as for each environment call I had to get the code that calls the robot. It would call it but with extra parameters which would change the location. Adding five on the y would move the prey in front, subtracting five puts the prey behind the predator, adding five on the x puts the prey to the right of the robot, and subtracting five on the x puts the prey to the left of the predator.
 	When running the first test at three different number of generations, I got interesting results. This was before the environments were implemented. At 500 generations, the predator was showing signs, as it was slowly edging its way toward the prey robot, and the prey robot was moving a little. 
 At 1000 generations, it showed signs of advancement, as the predator robot began to walk around and soon started moving toward the prey. The prey began to move away from the predator. 
 Finally, was the 2000 generation test, which gave really good results. The predator robot began walking to it’s right, and eventually turned to it’s left and moved toward the prey and bumping right into it. The prey tried it’s best to walk away but the predator was walking fast toward it.
 But to show evolution occurred I had to test this again with different prey positions. I decided to run 2000 generation for the different environments. The results for each environment were great as in each case the predator robot made its way to the prey no matter where it was placed in the environment. (Note: The robot on the right in the picture above is the prey. I forgot to change it to blue when running the test.) The only problem was that the prey robot would move away from the predator initially, but would either stop or fall over, allowing the predator to catch it. This only occurred when the environments were implemented. 
	
  Overall the project went well as the predator and prey task was performed, and the robot evolved to accomplish this task. The project wasn’t extremely difficult, but there were many moments where it took me a while to figure out what to do. If I had an extra year to expand upon this project, I would simulate Darwin’s survival of the fittest. In doing so, I would have many different types of predators: four legged, three legged, six legged, wheeled. In the environment would be many prey robots. The task is to see which predator robot can “capture” the most prey robots. To do this I would need collision detection to count the moment a predator collides with prey, and somehow remove the light source from the prey. This would see what type of predator robot will survive and is best fit. It can easily be done, creating the legged robots, but the wheeled robot will be very difficult to build. Also, I feel like it would take a while to run a simulation with so many robots moving about. The fitness function could remain the same for each predator, as it is trying to reduce the distance between it and the nearest robot it sees (Assuming the other light sources in the environment don’t interfere with the light sensor). I really liked using pyrosim and can’t wait to see what improvements it will get in the future.

